{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user psycopg2-binary\n",
    "!pip install --user sql_magic\n",
    "\n",
    "import sys\n",
    "import pprint\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy these settings from https://platform.adobe.com/query/configuration\n",
    "connection = psycopg2.connect(\n",
    "    sslmode='require',\n",
    "     host='experienceplatform.platform-query.adobe.io',\n",
    "     port='80',\n",
    "     dbname='prod:all',\n",
    "     user='907075E95BF479EC0A495C73@AdobeOrg',\n",
    "     password='eNqrVqowLVWyUsrMLY7PSzTUzU6t1DXUS04tUtJRSsxJB8oEBRuZminVAgALngwl.eNplU21v2jAQ_i_52JFiO7aTVJq0lJSXQaBQWpYKKXJsh5pCHCWmK63632dStEmrP5x8j-_1ufO7o4Rz5UASeCEGVoQAZFAKQHMMXUQZdbEokBsAz4qcIFowIUIisoOETsfhOyVLk7VBGK-yg8qqHTOFrvf29dDI-vMNRT7tU0IIDf2eF_X9PgAAAvgjEjqXo9gaN4YZaU3f104jm0bpcu1crZ0nY6rmqttV-8YtGbxkJ4ed3qjykuv9Ce6ezbsvsJtuNyRdLZ7S5cik2_5T0gMgiW_gZHWDHgcWW02fZ4P0bbZKjsn-UU3uwHG-5GixTeF0eY9mSxEnoD-YgvR3EkevSdyP5qvFS7p_-LmI1s6HLdQcK9m2y23ezOhnWVqUNRY7F2nVYmPV-9EoGg-T5cPk1qdDOu7NUm_uz6M7_L09p67_8k8ohTQIsZfJAEOJc0t4gYSLOcEu48JzARGY5sTnVNIz_7X5Mj-Y-SIEIUHQJYEsXOz5yGU-yl0_Z9LHgQ8CHJz9NbfetSw37MLWXV9AH3Dm5YiGxUXsx4u7Zbr4NUSRnZ2_HE7HCIYwHrSJJftMTCABuE1s4b1WFiUhRdJj_LQgVr0-TpojC2nUO6hjNfimw_H1bNO2L18rVcsmU6W1CygGp3OiheuWZCtLJTrnCXdqyUSm6w0r1RszFmk6dh3V6cZ2NkihL6tabyU3UtzWWhy46enSyFfzxa7WO2m9D8IuMJd7VrKNXVZWqc6_leQ2n42UMfP_H3E-_gBLufnI.eNoBAAH__jKkqFTyFP-Oo56QmY-1Prm2MjvtaqbZuZfvEBZbKS5NlpC53Yf4jy2Xqjtgv6EJgPLsGhJo0CAxOt6wikswlFYypSaWAAQEuhvcnSEyQNv0sxaZD627wfOBWlzebquNujogZITTF5d_qNm33zq52v0WBf09PE4rVW8ps9Xo9pJ7FSmR1u155i8yZaRtXFZrS2cD3R17Aved9GAITY57HoIv006BrhoP0xLgbAszp8n0ey2_EQ8sUXLAuFJpelJE_9gvaqGYCnJu7N5_X0VDhedf8GPNNvoVO80KR9oyiEwDUf1k8rxrCZ-nNwKR7YiOddgGzCEwO5Nmt5kNY4nb2HLwJ3ub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable sql magic\n",
    "%load_ext sql_magic\n",
    "%config SQL.conn_name = 'connection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "show tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql df_result\n",
    "SELECT _experienceplatform.identification.ecid as ecid,\n",
    "_experienceplatform.carinsurance.insuranceKm as km,\n",
    "                     _experienceplatform.carinsurance.insuranceCarType as cartype,\n",
    "                     _experienceplatform.carinsurance.insuranceAge as age,\n",
    "                     _experienceplatform.carinsurance.insuranceGender as gender,\n",
    "                     _experienceplatform.carinsurance.insuranceCarBrand as carbrand,\n",
    "                     _experienceplatform.carinsurance.insuranceLeasing as leasing,\n",
    "                     _experienceplatform.carinsurance.insuranceCity as city,\n",
    "                    _experienceplatform.carinsurance.insuranceCountry as country,\n",
    "                     _experienceplatform.carinsurance.insuranceNationality as nationality,\n",
    "                    _experienceplatform.carinsurance.insurancePrimaryDriver as primaryuser,\n",
    "                     _experienceplatform.carinsurance.insurancePurchase as purchase,\n",
    "                    _experienceplatform.carinsurance.insuranceBasicPrice as pricequote,\n",
    "                    timestamp\n",
    "FROM emea_car_insurance_quotes_rtml_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config_properties = { \"n_estimators\": \"80\",\n",
    "                            \"max_depth\": \"5\"\n",
    "                            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import time, timedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import time, timedelta\n",
    "import os\n",
    "#from .utils import get_client_context\n",
    "\n",
    "def train_load(config_properties, data):\n",
    "    print(\"Training Data Load Start\")\n",
    "\n",
    "    #########################################\n",
    "    # Load Data\n",
    "    #########################################    \n",
    "    print('reading training data')\n",
    "    df1 = data\n",
    "\n",
    "    df1 = df1[['ecid', 'km', 'cartype', 'age', 'gender', 'carbrand', 'leasing', 'city', \n",
    "           'country', 'nationality', 'primaryuser', 'purchase', 'pricequote', 'timestamp']]\n",
    "    \n",
    "    #########################################\n",
    "    # Data Rollup\n",
    "    ######################################### \n",
    "    df1['timestamp'] = pd.to_datetime(df1.timestamp)\n",
    "    df1['hour'] = df1['timestamp'].dt.hour.astype(int)\n",
    "    df1['dayofweek'] = df1['timestamp'].dt.dayofweek\n",
    "    \n",
    "    df1.loc[(df1['purchase'] == 'yes'), 'purchase'] = 1\n",
    "    df1.purchase.fillna(0, inplace=True)\n",
    "    df1['purchase'] = df1['purchase'].astype(int)\n",
    "    \n",
    "    df1.dropna(subset = ['ecid'], inplace=True)\n",
    "    df1['ecid'] = df1['ecid'].astype(str)\n",
    "    df_conv_dict = df1.groupby('ecid').max()[['purchase']]\n",
    "    df_conv_dict = df_conv_dict.to_dict()\n",
    "    \n",
    "    idx = df1.groupby('ecid')['timestamp'].transform(max) == df1['timestamp']\n",
    "    df1 = df1[idx]\n",
    "    df1 = df1.drop_duplicates(subset = 'ecid', keep = 'last', inplace = False)\n",
    "    df1['purchase'] = df1['ecid'].map(df_conv_dict['purchase'])\n",
    "    \n",
    "    #########################################\n",
    "    # Data Preparation/Feature Engineering\n",
    "    #########################################      \n",
    "    \n",
    "    df1['carbrand'] = df1['carbrand'].str.lower()\n",
    "    df1['country'] = df1['country'].str.lower()\n",
    "    df1.loc[(df1['carbrand'] == 'vw'), 'carbrand'] = 'volkswagen'\n",
    "    df1.loc[(df1['carbrand'] == 'citroen'), 'carbrand'] = 'cadillac'\n",
    "    df1.loc[(df1['carbrand'] == 'opel'), 'carbrand'] = 'bmw'\n",
    "    df1.loc[(df1['carbrand'] == 'mini'), 'carbrand'] = 'volkswagen'\n",
    "    \n",
    "    df1.loc[(df1['cartype'] == 'SUV / Geländewagen') | (df1['cartype'] == 'SUV / Tout terrain'), 'cartype'] = 'suv'\n",
    "    df1.loc[(df1['cartype'] == 'Kleinwagen') | (df1['cartype'] == 'Untere Mittelklasse') | (df1['cartype'] == 'Mikroklasse'), 'cartype'] = 'hatchback'\n",
    "    df1.loc[(df1['cartype'] == 'Mittelklasse') | (df1['cartype'] == 'Obere Mittelklasse'), 'cartype'] = 'sedan'\n",
    "    df1.loc[(df1['cartype'] == 'Kompaktvan / Minivan'), 'cartype'] = 'minivan'\n",
    "    df1.loc[(df1['cartype'] == 'Cabriolet / Roadster'), 'cartype'] = 'convertible'\n",
    "    df1.loc[(df1['cartype'] == 'Coupé / Sportwagen'), 'cartype'] = 'coupe'\n",
    "    df1.loc[(df1['cartype'] == 'dataLayerNull'), 'cartype'] = pd.np.nan\n",
    "    df1.loc[(df1['cartype'] == 'Luxusklasse'), 'cartype'] = 'luxury'\n",
    "    df1.loc[(df1['cartype'] == 'Strasse'), 'cartype'] = 'mpv'\n",
    "    \n",
    "    df1.loc[(df1['leasing'] == 'FALSE'), 'leasing'] = 'no'\n",
    "    df1.loc[df1['country'] == 'at', 'country'] = 'austria'\n",
    "    df1.loc[(df1['leasing'] == 'dataLayerNull'), 'leasing'] = pd.np.nan\n",
    "    df1.loc[(df1['gender'] == 'dataLayerNull'), 'gender'] = pd.np.nan\n",
    "    df1.loc[(df1['carbrand'] == 'dataLayerNull'), 'carbrand'] = pd.np.nan\n",
    "\n",
    "    df1['age'].fillna(df1['age'].median(), inplace=True)\n",
    "    df1['gender'].fillna('notgiven', inplace=True)\n",
    "    df1['leasing'].fillna('notgiven', inplace=True)\n",
    "    df1['carbrand'].fillna('bmw', inplace=True)\n",
    "    df1['country'].fillna('germany', inplace=True)\n",
    "    df1['cartype'].fillna('na', inplace=True)\n",
    "    df1['primaryuser'].fillna('na', inplace=True)\n",
    "    df1['nationality'].fillna('na', inplace=True)\n",
    "    df1['km'].fillna('na', inplace=True)\n",
    "    \n",
    "    df1['city'] = df1.groupby('country')['city'].transform(lambda x : x.fillna(x.mode()))\n",
    "    df1.dropna(subset = ['pricequote'], inplace=True)\n",
    "    \n",
    "    #grouping\n",
    "    grouping_cols = ['carbrand', 'cartype', 'city', 'country']\n",
    "    \n",
    "    for col in grouping_cols:\n",
    "        df_idx = pd.DataFrame(df1[col].value_counts().head(6))\n",
    "\n",
    "        def grouping(x):\n",
    "            if x in df_idx.index:\n",
    "                return x\n",
    "            else:\n",
    "                return \"Others\"\n",
    "        df1[col] = df1[col].apply(lambda x: grouping(x))\n",
    "        \n",
    "    def age(x):\n",
    "        if x < 20:\n",
    "            return \"u20\"\n",
    "        elif x > 19 and x < 29:\n",
    "            return \"20-28\"\n",
    "        elif x > 28 and x < 43:\n",
    "            return \"29-42\"\n",
    "        elif x > 42 and x < 55:\n",
    "            return \"43-54\"\n",
    "        elif x > 54 and x < 65:\n",
    "            return \"55-64\"\n",
    "        elif x >= 65: \n",
    "            return \"65+\"\n",
    "        else: \n",
    "            return \"Others\"\n",
    "        \n",
    "    df1['age'] = df1['age'].astype(int)\n",
    "    df1['age_bucket'] = df1['age'].apply(lambda x: age(x))\n",
    "    \n",
    "    df_final = df1[['hour', 'dayofweek','age_bucket', 'gender', 'city',  \n",
    "       'country', 'carbrand', 'cartype', 'leasing', 'pricequote', 'purchase']]\n",
    "    \n",
    "    cat_cols = ['age_bucket', 'gender', 'city', 'dayofweek', 'country', 'carbrand', 'cartype', 'leasing']\n",
    "    df_final = pd.get_dummies(df_final, columns = cat_cols)\n",
    "    \n",
    "    dataframe = df_final.copy()\n",
    "    \n",
    "    print(\"Training Data Load Finish\")\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = train_load(train_config_properties, df_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, val = train_test_split(df_final, test_size = 0.2, random_state = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_set.drop('purchase', axis=1)\n",
    "train_feats = train_x.columns.tolist()\n",
    "print(\"Totals Features: \",len(train_feats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import os\n",
    "import tarfile\n",
    "import subprocess\n",
    "\n",
    "def underSample(data):\n",
    "    conv = data[data['purchase'] > 0]\n",
    "    non_conv = data[data['purchase'] == 0]\n",
    "    sample_size = len(conv)\n",
    "    non_sample = non_conv.sample(n = sample_size)\n",
    "    frames = [conv, non_sample]\n",
    "    result = pd.concat(frames)\n",
    "    return result\n",
    "\n",
    "class RandomForest():\n",
    "    def __init__(self, config_properties, feat_len):\n",
    "        print(\"initiating model\")\n",
    "        self.n_estimators = int(config_properties['n_estimators'])\n",
    "        self.max_depth = int(config_properties['max_depth'])\n",
    "        self.feature_len = feat_len\n",
    "        self.model = RandomForestClassifier(n_estimators=self.n_estimators, max_depth=self.max_depth, random_state=32)\n",
    "\n",
    "    def make_tarfile(self, output_filename, source_dir):\n",
    "        with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "            tar.add(source_dir, arcname=os.path.basename(source_dir))\n",
    "    \n",
    "    def generate_onnx_resources(self):        \n",
    "        install_dir = os.path.expanduser('~/my-workspace')\n",
    "        print(\"Generating Onnx\")\n",
    "        try:\n",
    "            subprocess.check_call([\"conda\", \"uninstall\", \"-y\", \"protobuf\"])\n",
    "        except:\n",
    "            print(\"protobuf not installed via conda\")\n",
    "        \n",
    "        subprocess.check_call([\"python\", '-m', 'pip', 'install', 'skl2onnx'])\n",
    "        \n",
    "        from skl2onnx import convert_sklearn\n",
    "        from skl2onnx.common.data_types import FloatTensorType\n",
    "        \n",
    "        # ONNX-ification\n",
    "        initial_type = [('float_input', FloatTensorType([None, self.feature_len]))]\n",
    "\n",
    "        print(\"Converting Model to Onnx\")\n",
    "        onx = convert_sklearn(self.model, initial_types=initial_type)\n",
    "             \n",
    "        with open(\"model_new.onnx\", \"wb\") as f:\n",
    "            f.write(onx.SerializeToString())\n",
    "            \n",
    "        self.make_tarfile('model_new.tar.gz', 'model_new.onnx')\n",
    "        print(\"Model onnx created\")\n",
    "        \n",
    "def train(config_properties, data):\n",
    "\n",
    "    print(\"Train Start\")\n",
    "      \n",
    "    # UnderSampling\n",
    "    #result = underSample(data)\n",
    "    y_train = data['purchase']\n",
    "    X_train = data.drop('purchase', axis=1)\n",
    "    feat_len = len(X_train.columns)\n",
    "    \n",
    "    # Fit model\n",
    "    lead_score = RandomForest(config_properties, feat_len)\n",
    "    print(\"fitting model\")\n",
    "    model = lead_score.model\n",
    "    print(X_train.shape)\n",
    "    model.fit(X_train, y_train)\n",
    "    lead_score.generate_onnx_resources()\n",
    "    print(\"Train Complete\")\n",
    "    return lead_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_config_properties, train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Onnx Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x = val.drop('purchase', axis=1)\n",
    "test_list = val_x.head().values.tolist()\n",
    "print(len(test_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_test = np.array(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as rt\n",
    "from onnxruntime.capi.onnxruntime_pybind11_state import InvalidArgument\n",
    "\n",
    "sess = rt.InferenceSession(\"model_new.onnx\")\n",
    "input_name = sess.get_inputs()[0].name\n",
    "prob_name = sess.get_outputs()[1].name\n",
    "try:\n",
    "    pred_onx = sess.run([prob_name],{input_name: X_test.astype(np.float32)})[0]\n",
    "    print('shape ={0} and predicted probabilities={1}'.format(X_test.shape, pred_onx))\n",
    "except (RuntimeError, InvalidArgument) as e:\n",
    "    print(\"ERROR with Shape={0} - {1}\".format(X_test.shape, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in pred_onx:\n",
    "    preds.append(i[1])\n",
    "\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Handler\n",
    "For handling incoming json data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize  \n",
    "import onnxruntime as rt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_live_df(jsonfile):\n",
    "    with open(jsonfile) as data_file:    \n",
    "        data = json.load(data_file)  \n",
    "    live_df = pd.io.json.json_normalize(data)\n",
    "    live_df.rename(columns = {'body.xdmEntity._experienceplatform.identification.ecid' : 'ecid',\n",
    "                          'body.xdmEntity.timestamp' : 'timestamp',\n",
    "                          'body.xdmEntity._experienceplatform.carinsurance.insuranceAge' : 'age',\n",
    "                          'body.xdmEntity._experienceplatform.carinsurance.insuranceBasicPrice' : 'pricequote',\n",
    "                          'body.xdmEntity._experienceplatform.carinsurance.insuranceCarBrand' : 'carbrand',\n",
    "                          'body.xdmEntity._experienceplatform.carinsurance.insuranceCarType' : 'cartype',\n",
    "                          'body.xdmEntity._experienceplatform.carinsurance.insuranceCity' : 'city',\n",
    "                          'body.xdmEntity._experienceplatform.carinsurance.insuranceCountry' : 'country',\n",
    "                          'body.xdmEntity._experienceplatform.carinsurance.insuranceGender' : 'gender',\n",
    "                          'body.xdmEntity._experienceplatform.carinsurance.insuranceLeasing' : 'leasing'}, inplace=True)\n",
    "    return live_df\n",
    "\n",
    "def age(x):\n",
    "    if x < 20:\n",
    "        return \"u20\"\n",
    "    elif x > 19 and x < 29:\n",
    "        return \"20-28\"\n",
    "    elif x > 28 and x < 43:\n",
    "        return \"29-42\"\n",
    "    elif x > 42 and x < 55:\n",
    "        return \"43-54\"\n",
    "    elif x > 54 and x < 65:\n",
    "        return \"55-64\"\n",
    "    elif x >= 65: \n",
    "        return \"65+\"\n",
    "    else: \n",
    "        return \"Others\"\n",
    "\n",
    "def get_score_df(live_df):\n",
    "    dfs = live_df[['ecid','timestamp', 'age', 'pricequote', 'carbrand', 'cartype', 'city', 'country', 'gender', 'leasing']]   \n",
    "    # get values from loopkup table for matching mcids\n",
    "    dfs['timestamp'] = pd.to_datetime(dfs['timestamp'])\n",
    "    dfs['hour'] = dfs['timestamp'].dt.hour\n",
    "    dfs['dayofweek'] = dfs['timestamp'].dt.dayofweek\n",
    "    dfs['hour'] = dfs['hour'].astype(int)\n",
    "    dfs['dayofweek'] = dfs['dayofweek'].astype(int)\n",
    "    dfs.drop('timestamp', axis=1, inplace=True)\n",
    "\n",
    "    dfs['age'] = dfs['age'].astype(int)\n",
    "    dfs['age_bucket'] = dfs['age'].apply(lambda x: age(x))   \n",
    "    dfs.drop('age', axis=1, inplace=True)\n",
    "    \n",
    "    cats = ['age_bucket', 'gender', 'city', 'country', 'carbrand', 'cartype', 'leasing']\n",
    "    \n",
    "    dfs = pd.get_dummies(dfs, columns = cats)\n",
    "    \n",
    "    X_score = dfs.drop('ecid', axis=1) \n",
    "    train_feats = ['hour', 'pricequote', 'age_bucket_29-42', 'age_bucket_43-54', 'age_bucket_55-64', 'gender_female', 'gender_male', 'city_Brussels', 'city_Zurich', 'dayofweek_0', 'dayofweek_1', 'dayofweek_2',\n",
    " 'dayofweek_3', 'dayofweek_4', 'dayofweek_5', 'dayofweek_6', 'country_australia', 'country_belgium', 'country_india', 'country_switzerland', 'carbrand_alfaromeo', 'carbrand_audi', 'carbrand_bmw',\n",
    " 'carbrand_dodge', 'carbrand_saab', 'carbrand_volvo', 'cartype_convertible', 'cartype_hatchback', 'cartype_minivan', 'cartype_suv', 'leasing_no', 'leasing_yes']\n",
    "    \n",
    "    score_feats = X_score.columns.values.tolist()\n",
    "    missing_feats = list(set(train_feats) - set(score_feats))\n",
    "    extra_feats = list(set(score_feats) - set(train_feats))\n",
    "    for c in extra_feats:\n",
    "        X_score.drop(c, axis=1, inplace=True)\n",
    "    for c in missing_feats:\n",
    "        X_score[c] = 0\n",
    "    X_score = X_score[train_feats]\n",
    "    ecids = dfs['ecid'].tolist()\n",
    "    \n",
    "    return ecids, X_score\n",
    "\n",
    "def predict(jsonfile):\n",
    "    \n",
    "    json_df = get_live_df(jsonfile)\n",
    "    ecids, score_df = get_score_df(json_df)\n",
    "    payload = np.array(score_df.values.tolist())\n",
    "    \n",
    "    sess = rt.InferenceSession(\"model_new.onnx\")\n",
    "    input_name = sess.get_inputs()[0].name\n",
    "    prob_name = sess.get_outputs()[1].name\n",
    "    pred_onx = sess.run([prob_name],{input_name: payload.astype(np.float32)})[0]\n",
    "    \n",
    "    preds = [i[1] for i in pred_onx]\n",
    "    result = {}\n",
    "    for i in range(len(ecids)):\n",
    "        result[ecids[i]] = preds[i]\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict Output of sample json feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict('sample_demo.json')\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
